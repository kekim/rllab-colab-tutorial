{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ddpg_box2d_test.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"YJGCe-b7JSO4","colab_type":"code","colab":{}},"cell_type":"code","source":["!apt-get -qq -y install libnvtoolsext1 > /dev/null\n","!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n","!apt-get -qq -y install xvfb freeglut3-dev ffmpeg > /dev/null\n","\n","!pip install -q path.py\n","!pip install -q pyprind\n","!pip install -q cached_property\n","!pip install -q gym==0.7.4\n","!pip install -q theano==0.8.2\n","!pip install -q git+https://github.com/neocxi/Lasagne.git@484866cf8b38d878e92d521be445968531646bb8#egg=Lasagne\n","  \n","!pip install -q pyopengl pyglet pyvirtualdisplay box2d-py\n","\n","!git clone https://github.com/kekim/rllab.git rllab-git\n","  \n","!cp -a ./rllab-git/* ."],"execution_count":0,"outputs":[]},{"metadata":{"id":"isn8nKhR1Nyh","colab_type":"code","colab":{}},"cell_type":"code","source":["from pyvirtualdisplay import Display\n","display = Display(visible=0, size=(1024, 768))\n","display.start()\n","import os\n","os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C7VujhHav6Mz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"ed17022f-3442-4a67-8cab-4b26b0cf4a87"},"cell_type":"code","source":["from rllab.algos.ddpg import DDPG\n","from rllab.envs.gym_env import GymEnv\n","from rllab.envs.normalized_env import normalize\n","from rllab.misc.instrument import run_experiment_lite\n","from rllab.exploration_strategies.ou_strategy import OUStrategy\n","from rllab.policies.deterministic_mlp_policy import DeterministicMLPPolicy\n","from rllab.q_functions.continuous_mlp_q_function import ContinuousMLPQFunction\n","\n","\n","def run_task(*_):\n","    env = normalize(GymEnv(\"LunarLanderContinuous-v2\", record_video=True, force_reset=True))\n","\n","    policy = DeterministicMLPPolicy(\n","        env_spec=env.spec,\n","        # The neural network policy should have two hidden layers, each with 32 hidden units.\n","        hidden_sizes=(32, 32)\n","    )\n","\n","    es = OUStrategy(env_spec=env.spec)\n","\n","    qf = ContinuousMLPQFunction(env_spec=env.spec)\n","\n","    algo = DDPG(\n","        env=env,\n","        policy=policy,\n","        es=es,\n","        qf=qf,\n","        batch_size=32,\n","        max_path_length=100,\n","        epoch_length=1000,\n","        min_pool_size=10000,\n","        n_epochs=1000,\n","        discount=0.99,\n","        scale_reward=0.01,\n","        qf_learning_rate=1e-3,\n","        policy_learning_rate=1e-4,\n","        # Uncomment both lines (this and the plot parameter below) to enable plotting\n","        # plot=True,\n","    )\n","    algo.train()\n","\n","# run_task()\n","\n","run_experiment_lite(\n","    run_task,\n","    # Number of parallel workers for sampling\n","    n_parallel=1,\n","    # Only keep the snapshot parameters for the last iteration\n","    snapshot_mode=\"last\",\n","    # Specifies the seed for the experiment. If this is not provided, a random seed\n","    # will be used\n","    seed=1,\n","    # plot=True,\n",")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["python /content/scripts/run_experiment_lite.py  --n_parallel '1'  --snapshot_mode 'last'  --seed '1'  --exp_name 'experiment_2019_01_14_06_54_36_0001'  --log_dir '/content/data/local/experiment/experiment_2019_01_14_06_54_36_0001'  --use_cloudpickle 'True'  --args_data 'gASVbAQAAAAAAACMF2Nsb3VkcGlja2xlLmNsb3VkcGlja2xllIwOX2ZpbGxfZnVuY3Rpb26Uk5QoaACMD19tYWtlX3NrZWxfZnVuY5STlGgAjA1fYnVpbHRpbl90eXBllJOUjAhDb2RlVHlwZZSFlFKUKEsASwBLBksPS0dDZnQAdAFkAWQCZAJkA40DgwF9AXQCfAFqA2QPZAWNAn0CdAR8AWoDZAaNAX0DdAV8AWoDZAaNAX0EdAZ8AXwCfAN8BGQEZAdkCGQJZAhkCmQLZAxkDWQOjQ19BXwFageDAAEAZABTAJQoTowYTHVuYXJMYW5kZXJDb250aW51b3VzLXYylIiMDHJlY29yZF92aWRlb5SMC2ZvcmNlX3Jlc2V0lIaUSyCMCGVudl9zcGVjlIwMaGlkZGVuX3NpemVzlIaUaA+FlEtkTegDTRAnRz/vrhR64UeuRz+EeuFHrhR7Rz9QYk3S8an8Rz8aNuLrHEMtKIwDZW52lIwGcG9saWN5lIwCZXOUjAJxZpSMCmJhdGNoX3NpemWUjA9tYXhfcGF0aF9sZW5ndGiUjAxlcG9jaF9sZW5ndGiUjA1taW5fcG9vbF9zaXpllIwIbl9lcG9jaHOUjAhkaXNjb3VudJSMDHNjYWxlX3Jld2FyZJSMEHFmX2xlYXJuaW5nX3JhdGWUjBRwb2xpY3lfbGVhcm5pbmdfcmF0ZZR0lEsgSyCGlHSUKIwJbm9ybWFsaXpllIwGR3ltRW52lIwWRGV0ZXJtaW5pc3RpY01MUFBvbGljeZSMBHNwZWOUjApPVVN0cmF0ZWd5lIwWQ29udGludW91c01MUFFGdW5jdGlvbpSMBEREUEeUjAV0cmFpbpR0lCiMAV+UaBNoFGgVaBaMBGFsZ2+UdJSMHjxpcHl0aG9uLWlucHV0LTMtN2Y3YzRkYjMwZDI0PpSMCHJ1bl90YXNrlEsKQyoAARICAgEEAggDDAIMAgIBAgECAQIBAgECAQIBAgECAQIBAgECAQIBCASUKSl0lFKUSv////+MCF9fbWFpbl9flIeUUpR9lCiMB2dsb2JhbHOUfZQoaCeMKHJsbGFiLmV4cGxvcmF0aW9uX3N0cmF0ZWdpZXMub3Vfc3RyYXRlZ3mUaCeTlGgjjBlybGxhYi5lbnZzLm5vcm1hbGl6ZWRfZW52lIwNTm9ybWFsaXplZEVudpSTlGgkjBJybGxhYi5lbnZzLmd5bV9lbnaUaCSTlGgpjBBybGxhYi5hbGdvcy5kZHBnlGgpk5RoJYwncmxsYWIucG9saWNpZXMuZGV0ZXJtaW5pc3RpY19tbHBfcG9saWN5lGglk5RoKIwrcmxsYWIucV9mdW5jdGlvbnMuY29udGludW91c19tbHBfcV9mdW5jdGlvbpRoKJOUdYwIZGVmYXVsdHOUTowEZGljdJR9lIwOY2xvc3VyZV92YWx1ZXOUTowGbW9kdWxllGg0jARuYW1llGgwjANkb2OUTowIcXVhbG5hbWWUaDB1dFIu'  --variant_data 'gAN9cQBYCAAAAGV4cF9uYW1lcQFYIwAAAGV4cGVyaW1lbnRfMjAxOV8wMV8xNF8wNl81NF8zNl8wMDAxcQJzLg=='\n"],"name":"stdout"}]},{"metadata":{"id":"OFyc24IdHbeA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}